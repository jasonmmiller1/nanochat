_wandb:
    value:
        cli_version: 0.21.3
        e:
            yyw8lqvqw7n5ltzva7jgr01rdyuquwe3:
                args:
                    - --depth=20
                    - --run=my_first_chatgpt
                cpu_count: 104
                cpu_count_logical: 208
                cudaVersion: "12.8"
                disk:
                    /:
                        total: "23443440275456"
                        used: "60984610816"
                email: jmille16@umbc.edu
                executable: /lambda/nfs/nanochat/.venv/bin/python3
                git:
                    commit: 4a87a0d19f30799b6c700285822dcca850adf6a4
                    remote: https://github.com/jasonmmiller1/nanochat.git
                gpu: NVIDIA H100 80GB HBM3
                gpu_count: 8
                gpu_nvidia:
                    - architecture: Hopper
                      cudaCores: 16896
                      memoryTotal: "85520809984"
                      name: NVIDIA H100 80GB HBM3
                      uuid: GPU-41d4f2f5-74d6-c121-757f-68cb1ffa4eda
                    - architecture: Hopper
                      cudaCores: 16896
                      memoryTotal: "85520809984"
                      name: NVIDIA H100 80GB HBM3
                      uuid: GPU-f21f7a60-4243-5b8d-97e2-f12e5a613560
                    - architecture: Hopper
                      cudaCores: 16896
                      memoryTotal: "85520809984"
                      name: NVIDIA H100 80GB HBM3
                      uuid: GPU-4df064a0-ca49-0d29-1e20-b7a81dc06f97
                    - architecture: Hopper
                      cudaCores: 16896
                      memoryTotal: "85520809984"
                      name: NVIDIA H100 80GB HBM3
                      uuid: GPU-479c0a7f-a207-5eb5-88db-64ed623f3889
                    - architecture: Hopper
                      cudaCores: 16896
                      memoryTotal: "85520809984"
                      name: NVIDIA H100 80GB HBM3
                      uuid: GPU-c77e611d-faf7-a129-1c83-8ee9c950bceb
                    - architecture: Hopper
                      cudaCores: 16896
                      memoryTotal: "85520809984"
                      name: NVIDIA H100 80GB HBM3
                      uuid: GPU-6a59a1ec-5f1e-cd19-60d9-b73b7bda82e0
                    - architecture: Hopper
                      cudaCores: 16896
                      memoryTotal: "85520809984"
                      name: NVIDIA H100 80GB HBM3
                      uuid: GPU-c1f653ff-659e-5741-7e98-3ff17e7a970c
                    - architecture: Hopper
                      cudaCores: 16896
                      memoryTotal: "85520809984"
                      name: NVIDIA H100 80GB HBM3
                      uuid: GPU-bbf07de8-dbdf-90ea-aec3-2ccdc1baee68
                host: 192-222-53-250
                memory:
                    total: "1902330568704"
                os: Linux-6.8.0-60-generic-x86_64-with-glibc2.35
                program: -m scripts.base_train
                python: CPython 3.10.12
                root: /lambda/nfs/nanochat
                startedAt: "2025-11-30T17:35:50.326830Z"
                writerId: yyw8lqvqw7n5ltzva7jgr01rdyuquwe3
        m: []
        python_version: 3.10.12
        t:
            "1":
                - 1
            "2":
                - 1
            "3":
                - 2
                - 13
                - 16
            "4": 3.10.12
            "5": 0.21.3
            "12": 0.21.3
            "13": linux-x86_64
core_metric_every:
    value: 2000
core_metric_max_per_task:
    value: 500
depth:
    value: 20
device_batch_size:
    value: 32
device_type:
    value: ""
embedding_lr:
    value: 0.2
eval_every:
    value: 250
eval_tokens:
    value: 10485760
final_lr_frac:
    value: 0
grad_clip:
    value: 1
matrix_lr:
    value: 0.02
max_seq_len:
    value: 2048
model_tag:
    value: ""
num_iterations:
    value: -1
resume_from_step:
    value: -1
run:
    value: my_first_chatgpt
sample_every:
    value: 2000
save_every:
    value: -1
target_flops:
    value: -1
target_param_data_ratio:
    value: 20
total_batch_size:
    value: 524288
unembedding_lr:
    value: 0.004
warmdown_ratio:
    value: 0.2
warmup_ratio:
    value: 0
weight_decay:
    value: 0
